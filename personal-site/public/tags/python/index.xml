<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Python on Jure Bevc</title>
    <link>https://jurebevc.com/tags/python/</link>
    <description>Recent content in Python on Jure Bevc</description>
    <image>
      <title>Jure Bevc</title>
      <url>https://jurebevc.com/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://jurebevc.com/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Fri, 18 Aug 2023 17:41:32 +0200</lastBuildDate><atom:link href="https://jurebevc.com/tags/python/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Web crawler</title>
      <link>https://jurebevc.com/posts/web-crawler/</link>
      <pubDate>Fri, 18 Aug 2023 17:41:32 +0200</pubDate>
      
      <guid>https://jurebevc.com/posts/web-crawler/</guid>
      <description>Since there are not many free tools available for quick and easy web scraping, I created my own web crawler for basic data scraping. The project is available on my GitHub. The web crawler uses the selenium framework with the geckodriver web driver to scrape websites and the Tkinter toolkit to create a simple GUI for quick use:
This crawler was used to scrape over 4000 vaccination tweets from Twitter. The dataset is available on Kaggle.</description>
    </item>
    
  </channel>
</rss>
